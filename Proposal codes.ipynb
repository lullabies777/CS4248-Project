{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "import pandas as pd \n",
    "from tqdm import tqdm\n",
    "from torchtext.legacy import data\n",
    "from torchtext.vocab import Vectors\n",
    "from torchtext.vocab import GloVe\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import nltk\n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "from nltk import word_tokenize\n",
    "\n",
    "text = data.Field(sequential = True, lower = True, tokenize = word_tokenize)\n",
    "term = data.Field(sequential = False, lower = True)\n",
    "polarity = data.Field(sequential = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, val_set = data.TabularDataset.splits(path=r'data/',\n",
    "                                        skip_header=True,\n",
    "                                        train='rest_train.csv',\n",
    "                                        validation='rest_test.csv',\n",
    "                                        format='csv',\n",
    "                                        fields=[('text', text),\n",
    "                                                ('term', term),\n",
    "                                                ('polarity', polarity)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = GloVe(name='6B',dim=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text.build_vocab(train_set, val_set, vectors=vectors)\n",
    "term.build_vocab(train_set, val_set, vectors=vectors)\n",
    "polarity.build_vocab(train_set, val_set)\n",
    "\n",
    "text_vocab_size = len(text.vocab)\n",
    "term_vocab_size = len(term.vocab)\n",
    "text_vector=text.vocab.vectors\n",
    "term_vector=term.vocab.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4545, 1529, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vocab_size, term_vocab_size, len(polarity.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the text field will now return both the data tensor and the length of the input text\n",
    "for x in data.BucketIterator(train_set, batch_size=len(train_set), shuffle=False):\n",
    "     max_len = x.text[1].max().numpy()\n",
    "for x in data.BucketIterator(val_set, batch_size=len(val_set), shuffle=False):\n",
    "     max_len = int(max(x.text[1].max().numpy(), max_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4545, 1529, 4538)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vocab_size, term_vocab_size, max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=512\n",
    "train_iter, val_iter = data.Iterator.splits(\n",
    "            (train_set, val_set),\n",
    "            sort_key=lambda x: len(x.text),\n",
    "            batch_sizes=(batch_size, len(val_set)), # batch_size only for training\n",
    "    )   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention_mlp(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim):\n",
    "        super(Attention_mlp, self).__init__()\n",
    "        self.wv = nn.Linear(embedding_dim, embedding_dim, bias= False)\n",
    "        self.wh = nn.Linear(hidden_dim, embedding_dim, bias = False)\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.fc1 = nn.Linear(2 * embedding_dim, 1, bias = False)\n",
    "    def forward(self, term, hidden):\n",
    "        #### term shape: batch_size * 1 * embedding\n",
    "        #### hidden shape: batch_size * seq_len * hidden_dim\n",
    "        term1 = self.wv(term).transpose(-2,-1)\n",
    "        # shape(batch_size * embedding_dim * 1)\n",
    "        hidden1 = self.wh(hidden).transpose(-2,-1)\n",
    "        # shape(batch_size * embedding_dim * seq_len)\n",
    "\n",
    "        M = torch.cat((hidden1, term1.expand(hidden1.size())), dim = -2)\n",
    "        # shape(batch_size * (2 * embedding_dim) * seq_len)\n",
    "\n",
    "        alpha = F.softmax(self.fc1(torch.tanh(M.transpose(-2,-1))), dim = -2).transpose(-2,-1)\n",
    "        # shape(batch_size * 1 * seq_len)\n",
    "        \n",
    "        h_star = torch.matmul(alpha, hidden)\n",
    "        # shape(batch_size * 1 * hidden_dim)\n",
    "        return h_star\n",
    "\n",
    "class Final_pred(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super(Final_pred, self).__init__()\n",
    "        self.wp = nn.Linear(hidden_dim, hidden_dim, bias = False)\n",
    "        self.wx = nn.Linear(hidden_dim, hidden_dim, bias = False)\n",
    "        self.ws = nn.Linear(hidden_dim, 3)\n",
    "\n",
    "    def forward(self, h_star, h_n):\n",
    "        o_star = torch.tanh(self.wp(h_star) + self.wx(h_n))\n",
    "        # shape(batch_size * 1 * hidden_dim)\n",
    "        y = self.ws(o_star)\n",
    "        # shape(batch_size * 1 * 3)\n",
    "        return y.squeeze(1)\n",
    "        \n",
    "class ATAE_LSTM(nn.Module):\n",
    "    def __init__(self, embedding_dim, num_hiddens, num_layers):\n",
    "        super(ATAE_LSTM, self).__init__()\n",
    "        self.text_embeddings = nn.Embedding(text_vocab_size, embedding_dim) # learnable embedding\n",
    "        self.term_embeddings = nn.Embedding(term_vocab_size, embedding_dim) #learnable embedding\n",
    "        self.text_embeddings = nn.Embedding.from_pretrained(text_vector,\n",
    "                                                            freeze=False) # static embedding\n",
    "        self.term_embeddings = nn.Embedding.from_pretrained(term_vector,\n",
    "                                                              freeze=False) #static embedding\n",
    "        self.lstm = nn.LSTM(input_size=2 * embedding_dim,\n",
    "                            hidden_size=num_hiddens,\n",
    "                            num_layers=num_layers,\n",
    "                            batch_first=True,\n",
    "                            bidirectional=True)\n",
    "\n",
    "        # self.wp = nn.Parameter(torch.Tensor(num_hiddens * 2, num_hiddens * 2))\n",
    "        # self.wx = nn.Parameter(torch.Tensor(num_hiddens * 2, num_hiddens * 2))\n",
    "        # self.ws = nn.Parameter(torch.Tensor(3, num_hiddens * 2))\n",
    "        \n",
    "        self.attn = Attention_mlp(embedding_dim,2 * num_hiddens)\n",
    "\n",
    "        self.final_pred = Final_pred(2 *num_hiddens)\n",
    "\n",
    "    def forward(self, text, term):\n",
    "        seq_len = len(text.t())\n",
    "        # print('text2:',text.size(1))\n",
    "        # print('term:',term.size())\n",
    "        e1 = self.text_embeddings(text)\n",
    "        # e1 shape(batch_size,seq_len, embedding_dim)\n",
    "        e2 = self.term_embeddings(term).expand(e1.size())\n",
    "\n",
    "        wv = torch.cat((e1, e2), dim=2)\n",
    "        # e.g.\n",
    "        # wv torch.Size([batch_size,seq_len,2*embedding_dim])\n",
    "\n",
    "        out, (h, c) = self.lstm(wv)  # output, (h, c)\n",
    "        # out shape(batch_size,seq_len, 2 * num_hiddens)\n",
    "        # h shape(num_layers * num_directions, batch_size, 2*num_hiddens)\n",
    "\n",
    "        r = self.attn(self.term_embeddings(term), out)\n",
    "        \n",
    "        # shape(batch_size * 1 * hidden_dim)\n",
    "        h_n = out[:, -1:, :]\n",
    "        # shape(batch_size * 1 * hidden_dim)\n",
    "        y = self.final_pred(r, h_n)\n",
    "        # shape(batch_size * 1 * 3)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Codes below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This allow you to automatically detect the device for training\n",
    "device = torch.device(\"cuda:\" + str(0) if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I implemented the proposed three components, GRU, Positional embedding and self-attention. You can use it for further ablation studies.\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, emsize, dropout = 0.1, max_len = max_len):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, emsize, 2) * (-math.log(10000.0) / emsize))\n",
    "        pe = torch.zeros(max_len, 1, emsize)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor, shape [seq_len, batch_size, embedding_dim]\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)\n",
    "\n",
    "class ATAE_GRU(nn.Module):\n",
    "    def __init__(self, embedding_dim, num_hiddens, num_layers, dropout=0.2):\n",
    "        super(ATAE_GRU, self).__init__()\n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.text_embeddings = nn.Embedding(text_vocab_size, embedding_dim) # learnable embedding\n",
    "        self.term_embeddings = nn.Embedding(term_vocab_size, embedding_dim) #learnable embedding\n",
    "        self.text_embeddings = nn.Embedding.from_pretrained(text_vector,\n",
    "                                                            freeze=False) # static embedding\n",
    "        self.term_embeddings = nn.Embedding.from_pretrained(term_vector,\n",
    "                                                              freeze=False) #static embedding\n",
    "        self.gru = nn.GRU(input_size=2 * embedding_dim,\n",
    "                            hidden_size=num_hiddens,\n",
    "                            num_layers=num_layers,\n",
    "                            batch_first=True,\n",
    "                            bidirectional=True,\n",
    "                            dropout=dropout)\n",
    "        \n",
    "        for name, p in self.gru.named_parameters():\n",
    "            if \"weight\" in name:\n",
    "                nn.init.orthogonal_(p)\n",
    "            elif \"bias\" in name:\n",
    "                nn.init.constant_(p, 0)\n",
    "        \n",
    "        self.attn = Attention_mlp(embedding_dim, 2 * num_hiddens)\n",
    "\n",
    "        self.final_pred = Final_pred(2 *num_hiddens)\n",
    "\n",
    "    def forward(self, text, term):\n",
    "        seq_len = len(text.t())\n",
    "        # print('text2:',text.size(1))\n",
    "        # print('term:',term.size())\n",
    "        e1 = self.text_embeddings(text)\n",
    "        # e1 shape(batch_size,seq_len, embedding_dim)\n",
    "        e2 = self.term_embeddings(term).expand(e1.size())\n",
    "\n",
    "        wv = torch.cat((e1, e2), dim=2)\n",
    "        # e.g.\n",
    "        # wv torch.Size([batch_size,seq_len,2*embedding_dim])\n",
    "\n",
    "        out, (h, c) = self.gru(wv)  # output, (h, c)\n",
    "        # out shape(batch_size,seq_len, 2 * num_hiddens)\n",
    "        # h shape(num_layers * num_directions, batch_size, 2*num_hiddens)\n",
    "\n",
    "        r = self.attn(self.term_embeddings(term), out)\n",
    "        \n",
    "        # shape(batch_size * 1 * hidden_dim)\n",
    "        h_n = out[:, -1:, :]\n",
    "        # shape(batch_size * 1 * hidden_dim)\n",
    "        y = self.final_pred(r, h_n)\n",
    "        # shape(batch_size * 1 * 3)\n",
    "        return y\n",
    "    \n",
    "class ATAE_GRU_Position(ATAE_GRU):\n",
    "    def __init__(self, embedding_dim, num_hiddens, num_layers, dropout=0.2):\n",
    "        super(ATAE_GRU_Position, self).__init__(embedding_dim, num_hiddens, num_layers, dropout)\n",
    "        # self.position_embeddings = nn.Embedding(pos_vocab_size, embedding_dim) #TODO: learnable embedding\n",
    "        self.position_encodings = PositionalEncoding(num_hiddens*2, dropout=dropout) #static encoding\n",
    "\n",
    "    def forward(self, text, term):\n",
    "        seq_len = len(text.t())\n",
    "        # print('text2:',text.size(1))\n",
    "        # print('term:',term.size())\n",
    "        e1 = self.text_embeddings(text)\n",
    "        # e1 shape(batch_size,seq_len, embedding_dim)\n",
    "        e2 = self.term_embeddings(term).expand(e1.size())\n",
    "\n",
    "        wv = torch.cat((e1, e2), dim=2)\n",
    "        # e.g.\n",
    "        # wv torch.Size([batch_size,seq_len,2*embedding_dim])\n",
    "\n",
    "        out, (h, c) = self.gru(wv)  # output, (h, c)\n",
    "        # out shape(batch_size,seq_len, 2 * num_hiddens)\n",
    "        # h shape(num_layers * num_directions, batch_size, 2*num_hiddens)\n",
    "\n",
    "        r = self.attn(self.term_embeddings(term), self.position_encodings(out.transpose(0,1)).transpose(0,1))\n",
    "        # shape(batch_size * 1 * hidden_dim)\n",
    "        h_n = out[:, -1:, :]\n",
    "        # shape(batch_size * 1 * hidden_dim)\n",
    "        y = self.final_pred(r, h_n)\n",
    "        # shape(batch_size * 1 * 3)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iter, net):\n",
    "    acc_sum, n = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(data_iter):\n",
    "            X1, X2, y = batch.text.to(device), batch.term.to(device), batch.polarity.to(device)\n",
    "            X1 = X1.permute(1, 0)\n",
    "            X2 = X2.unsqueeze(1)\n",
    "            y.data.sub_(1)  # index start from 0\n",
    "            if isinstance(net, torch.nn.Module):\n",
    "                net.eval()  \n",
    "                acc_sum += (net(X1,\n",
    "                                X2).argmax(dim=1) == y).float().sum().item()\n",
    "                net.train()  \n",
    "            else:\n",
    "                if ('is_training'\n",
    "                        in net.__code__.co_varnames): \n",
    "                    acc_sum += (net(X1, X2, is_training=False).argmax(\n",
    "                        dim=1) == y).float().sum().item()\n",
    "                else:\n",
    "                    acc_sum += (net(\n",
    "                        X1, X2).argmax(dim=1) == y).float().sum().item()\n",
    "            n += y.shape[0]\n",
    "    return acc_sum / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_iter, test_iter, net, loss, optimizer, num_epochs):\n",
    "    batch_count = 0\n",
    "    ret = ret = [[],[],[],[],[]]\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\n",
    "        for batch_idx, batch in enumerate(train_iter):\n",
    "            X1, X2, y = batch.text.to(device), batch.term.to(device), batch.polarity.to(device)\n",
    "            X1 = X1.permute(1, 0)\n",
    "            X2 = X2.unsqueeze(1)\n",
    "            y.data.sub_(1)  # index start from 0\n",
    "            y_hat = net(X1,X2)\n",
    "            l = loss(y_hat, y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_l_sum += l.item()\n",
    "            train_acc_sum += (y_hat.argmax(dim=1) == y).sum().item()\n",
    "            n += y.shape[0]\n",
    "            batch_count += 1\n",
    "        test_acc = evaluate_accuracy(test_iter, net)\n",
    "        print(\n",
    "            'epoch %d, loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec'\n",
    "            % (epoch + 1, train_l_sum / batch_count, train_acc_sum / n,\n",
    "               test_acc, time.time() - start))\n",
    "        ret[0].append(epoch + 1)\n",
    "        ret[1].append(train_l_sum / batch_count)\n",
    "        ret[2].append(train_acc_sum / n)\n",
    "        ret[3].append(test_acc)\n",
    "        ret[4].append(time.time() - start)\n",
    "                      \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline for ATAE_LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATAE_LSTM(\n",
      "  (text_embeddings): Embedding(4545, 300)\n",
      "  (term_embeddings): Embedding(1529, 300)\n",
      "  (lstm): LSTM(600, 150, batch_first=True, bidirectional=True)\n",
      "  (attn): Attention_mlp(\n",
      "    (wv): Linear(in_features=300, out_features=300, bias=False)\n",
      "    (wh): Linear(in_features=300, out_features=300, bias=False)\n",
      "    (fc1): Linear(in_features=600, out_features=1, bias=False)\n",
      "  )\n",
      "  (final_pred): Final_pred(\n",
      "    (wp): Linear(in_features=300, out_features=300, bias=False)\n",
      "    (wx): Linear(in_features=300, out_features=300, bias=False)\n",
      "    (ws): Linear(in_features=300, out_features=3, bias=True)\n",
      "  )\n",
      ")\n",
      "epoch 1, loss 0.9801, train acc 0.562, test acc 0.659, time 19.5 sec\n",
      "epoch 2, loss 0.4395, train acc 0.614, test acc 0.671, time 19.4 sec\n",
      "epoch 3, loss 0.2591, train acc 0.651, test acc 0.684, time 20.3 sec\n",
      "epoch 4, loss 0.1831, train acc 0.678, test acc 0.710, time 19.4 sec\n",
      "epoch 5, loss 0.1277, train acc 0.739, test acc 0.723, time 18.0 sec\n",
      "epoch 6, loss 0.0956, train acc 0.774, test acc 0.731, time 18.4 sec\n",
      "epoch 7, loss 0.0697, train acc 0.808, test acc 0.728, time 17.7 sec\n",
      "epoch 8, loss 0.0554, train acc 0.832, test acc 0.733, time 17.8 sec\n",
      "epoch 9, loss 0.0413, train acc 0.856, test acc 0.734, time 17.8 sec\n",
      "epoch 10, loss 0.0318, train acc 0.875, test acc 0.708, time 17.5 sec\n",
      "epoch 11, loss 0.0255, train acc 0.880, test acc 0.733, time 17.7 sec\n",
      "epoch 12, loss 0.0205, train acc 0.909, test acc 0.720, time 17.2 sec\n",
      "epoch 13, loss 0.0197, train acc 0.904, test acc 0.696, time 17.1 sec\n",
      "epoch 14, loss 0.0162, train acc 0.905, test acc 0.752, time 18.3 sec\n",
      "epoch 15, loss 0.0134, train acc 0.924, test acc 0.735, time 18.2 sec\n",
      "epoch 16, loss 0.0107, train acc 0.933, test acc 0.732, time 18.1 sec\n",
      "epoch 17, loss 0.0088, train acc 0.948, test acc 0.733, time 17.6 sec\n",
      "epoch 18, loss 0.0079, train acc 0.949, test acc 0.738, time 17.4 sec\n",
      "epoch 19, loss 0.0056, train acc 0.960, test acc 0.740, time 18.2 sec\n",
      "epoch 20, loss 0.0051, train acc 0.968, test acc 0.733, time 19.4 sec\n"
     ]
    }
   ],
   "source": [
    "embedding_dim, num_hiddens, num_layers = 300, 150, 1\n",
    "net = ATAE_LSTM(embedding_dim, num_hiddens, num_layers).to(device)\n",
    "print(net)\n",
    "lr, num_epochs = 0.001, 20\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "lstm_data = train(train_iter, val_iter, net, loss, optimizer, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline for ATAE_GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eric\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\rnn.py:60: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATAE_GRU(\n",
      "  (text_embeddings): Embedding(4545, 300)\n",
      "  (term_embeddings): Embedding(1529, 300)\n",
      "  (gru): GRU(600, 150, batch_first=True, dropout=0.2, bidirectional=True)\n",
      "  (attn): Attention_mlp(\n",
      "    (wv): Linear(in_features=300, out_features=300, bias=False)\n",
      "    (wh): Linear(in_features=300, out_features=300, bias=False)\n",
      "    (fc1): Linear(in_features=600, out_features=1, bias=False)\n",
      "  )\n",
      "  (final_pred): Final_pred(\n",
      "    (wp): Linear(in_features=300, out_features=300, bias=False)\n",
      "    (wx): Linear(in_features=300, out_features=300, bias=False)\n",
      "    (ws): Linear(in_features=300, out_features=3, bias=True)\n",
      "  )\n",
      ")\n",
      "epoch 1, loss 0.9785, train acc 0.568, test acc 0.665, time 13.6 sec\n",
      "epoch 2, loss 0.4058, train acc 0.629, test acc 0.671, time 14.0 sec\n",
      "epoch 3, loss 0.2609, train acc 0.653, test acc 0.704, time 13.8 sec\n",
      "epoch 4, loss 0.1813, train acc 0.685, test acc 0.725, time 13.2 sec\n",
      "epoch 5, loss 0.1258, train acc 0.735, test acc 0.723, time 12.6 sec\n",
      "epoch 6, loss 0.1013, train acc 0.768, test acc 0.739, time 13.4 sec\n",
      "epoch 7, loss 0.0730, train acc 0.797, test acc 0.741, time 13.3 sec\n",
      "epoch 8, loss 0.0550, train acc 0.824, test acc 0.739, time 13.9 sec\n",
      "epoch 9, loss 0.0468, train acc 0.841, test acc 0.754, time 14.0 sec\n",
      "epoch 10, loss 0.0394, train acc 0.848, test acc 0.752, time 13.7 sec\n",
      "epoch 11, loss 0.0331, train acc 0.872, test acc 0.735, time 13.4 sec\n",
      "epoch 12, loss 0.0291, train acc 0.874, test acc 0.735, time 12.0 sec\n",
      "epoch 13, loss 0.0246, train acc 0.884, test acc 0.746, time 13.1 sec\n",
      "epoch 14, loss 0.0204, train acc 0.891, test acc 0.737, time 12.6 sec\n",
      "epoch 15, loss 0.0157, train acc 0.909, test acc 0.736, time 13.4 sec\n",
      "epoch 16, loss 0.0125, train acc 0.920, test acc 0.743, time 13.5 sec\n",
      "epoch 17, loss 0.0107, train acc 0.940, test acc 0.742, time 13.7 sec\n",
      "epoch 18, loss 0.0084, train acc 0.948, test acc 0.748, time 12.9 sec\n",
      "epoch 19, loss 0.0066, train acc 0.953, test acc 0.740, time 12.9 sec\n",
      "epoch 20, loss 0.0052, train acc 0.963, test acc 0.732, time 12.9 sec\n"
     ]
    }
   ],
   "source": [
    "embedding_dim, num_hiddens, num_layers = 300, 150, 1\n",
    "net = ATAE_GRU(embedding_dim, num_hiddens, num_layers).to(device)\n",
    "print(net)\n",
    "lr, num_epochs = 0.001, 20\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "gru_data = train(train_iter, val_iter, net, loss, optimizer, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Baseline for ATAE_GRU+position-embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATAE_GRU_Position(\n",
      "  (text_embeddings): Embedding(4545, 300)\n",
      "  (term_embeddings): Embedding(1529, 300)\n",
      "  (gru): GRU(600, 150, batch_first=True, dropout=0.2, bidirectional=True)\n",
      "  (attn): Attention_mlp(\n",
      "    (wv): Linear(in_features=300, out_features=300, bias=False)\n",
      "    (wh): Linear(in_features=300, out_features=300, bias=False)\n",
      "    (fc1): Linear(in_features=600, out_features=1, bias=False)\n",
      "  )\n",
      "  (final_pred): Final_pred(\n",
      "    (wp): Linear(in_features=300, out_features=300, bias=False)\n",
      "    (wx): Linear(in_features=300, out_features=300, bias=False)\n",
      "    (ws): Linear(in_features=300, out_features=3, bias=True)\n",
      "  )\n",
      "  (position_encodings): PositionalEncoding(\n",
      "    (dropout): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      ")\n",
      "epoch 1, loss 1.0059, train acc 0.536, test acc 0.631, time 13.4 sec\n",
      "epoch 2, loss 0.4575, train acc 0.606, test acc 0.661, time 13.8 sec\n",
      "epoch 3, loss 0.3026, train acc 0.616, test acc 0.671, time 13.0 sec\n",
      "epoch 4, loss 0.1995, train acc 0.659, test acc 0.673, time 13.3 sec\n",
      "epoch 5, loss 0.1458, train acc 0.680, test acc 0.675, time 12.9 sec\n",
      "epoch 6, loss 0.1115, train acc 0.696, test acc 0.696, time 13.5 sec\n",
      "epoch 7, loss 0.0869, train acc 0.737, test acc 0.713, time 13.5 sec\n",
      "epoch 8, loss 0.0690, train acc 0.772, test acc 0.738, time 13.9 sec\n",
      "epoch 9, loss 0.0506, train acc 0.812, test acc 0.744, time 13.2 sec\n",
      "epoch 10, loss 0.0460, train acc 0.834, test acc 0.739, time 12.9 sec\n",
      "epoch 11, loss 0.0347, train acc 0.850, test acc 0.742, time 13.3 sec\n",
      "epoch 12, loss 0.0298, train acc 0.853, test acc 0.724, time 12.6 sec\n",
      "epoch 13, loss 0.0252, train acc 0.878, test acc 0.749, time 13.2 sec\n",
      "epoch 14, loss 0.0218, train acc 0.890, test acc 0.729, time 12.6 sec\n",
      "epoch 15, loss 0.0190, train acc 0.890, test acc 0.720, time 13.5 sec\n",
      "epoch 16, loss 0.0185, train acc 0.897, test acc 0.761, time 12.8 sec\n",
      "epoch 17, loss 0.0139, train acc 0.894, test acc 0.741, time 12.9 sec\n",
      "epoch 18, loss 0.0139, train acc 0.909, test acc 0.756, time 13.3 sec\n",
      "epoch 19, loss 0.0121, train acc 0.926, test acc 0.747, time 13.1 sec\n",
      "epoch 20, loss 0.0089, train acc 0.931, test acc 0.761, time 13.5 sec\n"
     ]
    }
   ],
   "source": [
    "embedding_dim, num_hiddens, num_layers = 300, 150, 1\n",
    "net = ATAE_GRU_Position(embedding_dim, num_hiddens, num_layers).to(device)\n",
    "print(net)\n",
    "lr, num_epochs = 0.001, 20\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "pos_data = train(train_iter, val_iter, net, loss, optimizer, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "def aggreation_data(path_to_single):\n",
    "    single_data = pd.read_csv(path_to_single)\n",
    "    single_data[\"polarity\"] = single_data[\"polarity\"].astype(str)\n",
    "    aggre_data = pd.DataFrame({\"text\":single_data.groupby(\"text\").count().index, \"term\":single_data.groupby(\"text\")[\"term\"].apply(lambda x:x.str.cat(sep='|')), \"polarity\":single_data.groupby(\"text\")[\"polarity\"].apply(lambda x:x.str.cat(sep='|'))})\n",
    "    aggre_data.to_csv(path_to_single[:-4]+'_aggregation'+'.csv', index=False)\n",
    "    # return aggre_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggreation_data('./data/rest_train.csv')\n",
    "aggreation_data('./data/rest_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.read_csv('./data/rest_train.csv')\n",
    "b = pd.read_csv('./data/rest_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = pd.read_csv('./data/rest_train_aggregation.csv')\n",
    "d = pd.read_csv('./data/rest_test_aggregation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>term</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>$160 for 2 filets, 2 sides, an appetizer and d...</td>\n",
       "      <td>filets|sides|appetizer|drinks</td>\n",
       "      <td>0|0|0|0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$20 for all you can eat sushi cannot be beaten.</td>\n",
       "      <td>sushi</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>$20 gets you unlimited sushi of a very high qu...</td>\n",
       "      <td>sushi|sushi places|quality</td>\n",
       "      <td>1|1|1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>$6 and there is much tasty food, all of it fre...</td>\n",
       "      <td>food</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>($200 for 2 glasses of champagne, not too expe...</td>\n",
       "      <td>glasses of champagne|bottle of wine|after dinn...</td>\n",
       "      <td>-1|-1|-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971</th>\n",
       "      <td>we were tired and cold when we got to the rest...</td>\n",
       "      <td>appetizers</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1972</th>\n",
       "      <td>word of advice, save room for pasta dishes and...</td>\n",
       "      <td>pasta dishes|tiramisu</td>\n",
       "      <td>1|1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1973</th>\n",
       "      <td>would have rather tried terrace in the sky or ...</td>\n",
       "      <td>price</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974</th>\n",
       "      <td>you can actually get 2 salads worth if u take ...</td>\n",
       "      <td>salads|lettuce</td>\n",
       "      <td>-1|0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975</th>\n",
       "      <td>yourself a favor and have dinner here and see ...</td>\n",
       "      <td>dinner</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1976 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "0     $160 for 2 filets, 2 sides, an appetizer and d...   \n",
       "1       $20 for all you can eat sushi cannot be beaten.   \n",
       "2     $20 gets you unlimited sushi of a very high qu...   \n",
       "3     $6 and there is much tasty food, all of it fre...   \n",
       "4     ($200 for 2 glasses of champagne, not too expe...   \n",
       "...                                                 ...   \n",
       "1971  we were tired and cold when we got to the rest...   \n",
       "1972  word of advice, save room for pasta dishes and...   \n",
       "1973  would have rather tried terrace in the sky or ...   \n",
       "1974  you can actually get 2 salads worth if u take ...   \n",
       "1975  yourself a favor and have dinner here and see ...   \n",
       "\n",
       "                                                   term  polarity  \n",
       "0                         filets|sides|appetizer|drinks   0|0|0|0  \n",
       "1                                                 sushi         0  \n",
       "2                            sushi|sushi places|quality     1|1|1  \n",
       "3                                                  food         1  \n",
       "4     glasses of champagne|bottle of wine|after dinn...  -1|-1|-1  \n",
       "...                                                 ...       ...  \n",
       "1971                                         appetizers         0  \n",
       "1972                              pasta dishes|tiramisu       1|1  \n",
       "1973                                              price        -1  \n",
       "1974                                     salads|lettuce      -1|0  \n",
       "1975                                             dinner         0  \n",
       "\n",
       "[1976 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0|0|0|0\n",
       "1              0\n",
       "2          1|1|1\n",
       "3              1\n",
       "4       -1|-1|-1\n",
       "          ...   \n",
       "1971           0\n",
       "1972         1|1\n",
       "1973          -1\n",
       "1974        -1|0\n",
       "1975           0\n",
       "Name: polarity, Length: 1976, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_term = max(a.groupby(\"text\").count().max()[0], b.groupby(\"text\").count().max()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "from nltk import word_tokenize\n",
    "\n",
    "text = data.Field(sequential = True, lower = True, tokenize = word_tokenize)\n",
    "term = data.Field(sequential = True, lower = True, tokenize = lambda x:x.split(\"|\"))\n",
    "polarity = data.Field(sequential = True, tokenize = lambda x:x.split(\"|\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, val_set = data.TabularDataset.splits(path=r'data/',\n",
    "                                        skip_header=True,\n",
    "                                        train='rest_train_aggregation.csv',\n",
    "                                        validation='rest_test_aggregation.csv',\n",
    "                                        format='csv',\n",
    "                                        fields=[('text', text),\n",
    "                                                ('term', term),\n",
    "                                                ('polarity', polarity)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "text.build_vocab(train_set, val_set, vectors=vectors)\n",
    "term.build_vocab(train_set, val_set, vectors=vectors)\n",
    "polarity.build_vocab(train_set, val_set)\n",
    "\n",
    "text_vocab_size = len(text.vocab)\n",
    "term_vocab_size = len(term.vocab)\n",
    "polarity_size = len(polarity.vocab)\n",
    "text_vector=text.vocab.vectors\n",
    "term_vector=term.vocab.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4545, 1530, 5)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vocab_size, term_vocab_size, len(polarity.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=512\n",
    "train_iter, val_iter = data.Iterator.splits(\n",
    "            (train_set, val_set),\n",
    "            sort_key=lambda x: len(x.text),\n",
    "            batch_sizes=(batch_size, len(val_set)), # batch_size only for training\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy_sa(data_iter, net):\n",
    "    acc_sum, n = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(data_iter):\n",
    "            X1, X2, y = batch.text.to(device), batch.term.to(device), batch.polarity.to(device)\n",
    "            X1 = X1.permute(1, 0)\n",
    "            X2 = X2.permute(1, 0)\n",
    "            y = y.permute(1, 0)\n",
    "            raw_mask = 1-(y==1).type(torch.long)\n",
    "            y = y.reshape(-1,1).squeeze()\n",
    "            # print(y, raw_mask)\n",
    "            mask = raw_mask.reshape(-1,1).squeeze() # get rid of padding\n",
    "            y.data.sub_(2)  # index start from 0\n",
    "            y *= mask\n",
    "            if isinstance(net, torch.nn.Module):\n",
    "                net.eval()  \n",
    "                res = net(X1, X2, 1-raw_mask).argmax(dim=1)*mask\n",
    "                acc_sum += ((res == (y*mask)).float().sum().item() - (1-mask).sum())\n",
    "                net.train()  \n",
    "            else:\n",
    "                if ('is_training'\n",
    "                        in net.__code__.co_varnames): \n",
    "                    acc_sum += (net(X1, X2, is_training=False).argmax(\n",
    "                        dim=1) == y).float().sum().item()\n",
    "                else:\n",
    "                    acc_sum += (net(\n",
    "                        X1, X2).argmax(dim=1) == y).float().sum().item()\n",
    "            n += (y.shape[0] - (1-mask).sum())\n",
    "    return acc_sum / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_sa(train_iter, test_iter, net, loss, optimizer, num_epochs):\n",
    "    batch_count = 0\n",
    "    ret = [[],[],[],[],[]]\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\n",
    "        # batch_count = 1\n",
    "        # n=1\n",
    "        for batch_idx, batch in enumerate(train_iter):\n",
    "            X1, X2, y = batch.text.to(device), batch.term.to(device), batch.polarity.to(device)\n",
    "            X1 = X1.permute(1, 0)\n",
    "            X2 = X2.permute(1, 0)\n",
    "            y = y.permute(1, 0)\n",
    "            \n",
    "            mask = 1-(y==1).type(torch.long)\n",
    "            y_hat = net(X1,X2,1-mask)\n",
    "            \n",
    "            y = y.reshape(-1,1).squeeze()\n",
    "            mask = mask.reshape(-1,1).squeeze() # get rid of padding\n",
    "            y.data.sub_(2)  # index start from 0\n",
    "            y *= mask\n",
    "            # print(y_hat, y.min())\n",
    "            l = loss(y_hat, y) * mask # get rid of padding\n",
    "            l=l.mean()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_l_sum += l.item()\n",
    "            train_acc_sum += ((y_hat.argmax(dim=1)*mask == (y*mask)).sum().item() - (1-mask).sum())\n",
    "            # print(mask, mask.sum(), (1-mask).sum(), y.shape[0], (y_hat.argmax(dim=1)*mask == (y*mask)).sum().item())\n",
    "            n += (y.shape[0] - (1-mask).sum())\n",
    "            batch_count += 1\n",
    "        test_acc = evaluate_accuracy_sa(test_iter, net)\n",
    "        print(\n",
    "            'epoch %d, loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec'\n",
    "            % (epoch + 1, train_l_sum / batch_count, train_acc_sum / n,\n",
    "               test_acc, time.time() - start))\n",
    "        ret[0].append(epoch + 1)\n",
    "        ret[1].append(train_l_sum / batch_count)\n",
    "        ret[2].append(train_acc_sum / n)\n",
    "        ret[3].append(test_acc)\n",
    "        ret[4].append(time.time() - start)\n",
    "                      \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline for ATAE_GRU+position-embedding+self-attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ATAE_GRU_Position_SA(ATAE_GRU_Position):\n",
    "    def __init__(self, embedding_dim, num_hiddens, num_layers, dropout=0.2, num_heads=2):\n",
    "        super(ATAE_GRU_Position_SA, self).__init__(embedding_dim, num_hiddens, num_layers, dropout)\n",
    "        self.multihead_attn = torch.nn.MultiheadAttention(2*num_hiddens, num_heads, dropout=dropout)\n",
    "        \n",
    "        self.num_attention_heads = num_heads\n",
    "        self.attention_head_size = int(2 * num_hiddens / num_heads)\n",
    "        self.all_head_size = 2 * num_hiddens\n",
    "        \n",
    "        self.query = nn.Linear(2 * num_hiddens, self.all_head_size)\n",
    "        self.key = nn.Linear(2 * num_hiddens, self.all_head_size)\n",
    "        self.value = nn.Linear(2 * num_hiddens, self.all_head_size)\n",
    "        \n",
    "        self.attn_dropout = nn.Dropout(dropout)\n",
    "        self.LayerNorm = nn.LayerNorm(2 * num_hiddens, eps=1e-12)\n",
    "        self.out_dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def transpose_for_scores(self, x):\n",
    "        new_x_shape = x.size()[:-1] + (self.num_attention_heads, self.attention_head_size)\n",
    "        x = x.view(*new_x_shape)\n",
    "        return x.permute(0, 2, 1, 3)\n",
    "\n",
    "    def forward(self, text_input, term_input, mask_input):\n",
    "        seq_len = len(text_input.t())\n",
    "        # print('text2:',text.size(1))\n",
    "        # print('term:',term.size())\n",
    "        e1 = self.text_embeddings(text_input)\n",
    "        # e1 shape(batch_size, seq_len, embedding_dim)\n",
    "        e2 = self.term_embeddings(term_input)\n",
    "        # e2 shape(batch_size, term_len, embedding_dim)\n",
    "        \n",
    "        # print(0, e1.shape, e2.shape)\n",
    "        \n",
    "        seq_len = e1.size(1)\n",
    "        term_len = e2.size(1)\n",
    "        #三维扩充为四维\n",
    "        e1 = e1.unsqueeze(1).repeat(1, term_len, 1, 1) # (batch_size, term_len, seq_len, embedding_dim)\n",
    "        e2 = e2.unsqueeze(2).repeat(1, 1, seq_len, 1) # (batch_size, term_len, seq_len, embedding_dim)\n",
    "        \n",
    "        # print(1, e1.shape, e2.shape)\n",
    "        \n",
    "        e1 = e1.reshape(-1, e1.size(2), e1.size(3)) # (batch_size * term_len, seq_len, embedding_dim)\n",
    "        e2 = e2.reshape(-1, e2.size(2), e2.size(3)) # (batch_size * term_len, seq_len, embedding_dim)\n",
    "        \n",
    "        # print(2, e1.shape, e2.shape)\n",
    "\n",
    "        wv = torch.cat((e1, e2), dim=2)\n",
    "        # e.g.\n",
    "        # wv torch.Size([batch_size*term_len,seq_len,2*embedding_dim])\n",
    "\n",
    "        out, (h, c) = self.gru(wv)  # output, (h, c)\n",
    "        # out shape(batch_size* term_len, seq_len, 2 * num_hiddens)\n",
    "        # h shape(num_layers * num_directions, batch_size * term_len, 2 * num_hiddens)\n",
    "        \n",
    "        # print(2.1, out.shape)\n",
    "\n",
    "        posenc = self.position_encodings(out.transpose(0,1)).transpose(0,1)\n",
    "        h_star = self.attn(e2, self.position_encodings(out.transpose(0,1)).transpose(0,1)) # (batch_size * term_len, 1, 2*hidden)\n",
    "        h_star = h_star.squeeze().reshape(-1, term_len, 2*self.num_hiddens) # (batch_size, term_len, 2*hidden)\n",
    "        out = out.squeeze().reshape(-1, term_len, seq_len, 2*self.num_hiddens) # (batch_size, term_len, 2*hidden)\n",
    "        \n",
    "        query = self.query(h_star).transpose(1, 0) # (batch_size, term_len, 2*hidden)\n",
    "        key = self.key(h_star).transpose(1, 0) # (batch_size, term_len, 2*hidden)\n",
    "        value = self.value(h_star).transpose(1, 0) # (batch_size, term_len, 2*hidden)\n",
    "        \n",
    "        attn_output, attn_output_weights = self.multihead_attn(query, key, value, key_padding_mask=mask_input) # (batch_size, term_len, 2*hidden),  (batch_size, term_len, term_len)\n",
    "        # shape(batch_size, term_len, 2*hidden)\n",
    "        h_n = out[:, :, -1:, :].squeeze()\n",
    "        # print(2.3, h_star.shape, h_n.shape)\n",
    "        # shape(batch_size, term_len, 2*hidden)\n",
    "        y = self.final_pred(h_star, h_n).reshape(-1, 3)\n",
    "        # shape(batch_size, term_len, 3)     \n",
    "            # print(3, y.shape)\n",
    "\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATAE_GRU_Position_SA(\n",
      "  (text_embeddings): Embedding(4545, 300)\n",
      "  (term_embeddings): Embedding(1530, 300)\n",
      "  (gru): GRU(600, 256, batch_first=True, dropout=0.2, bidirectional=True)\n",
      "  (attn): Attention_mlp(\n",
      "    (wv): Linear(in_features=300, out_features=300, bias=False)\n",
      "    (wh): Linear(in_features=512, out_features=300, bias=False)\n",
      "    (fc1): Linear(in_features=600, out_features=1, bias=False)\n",
      "  )\n",
      "  (final_pred): Final_pred(\n",
      "    (wp): Linear(in_features=512, out_features=512, bias=False)\n",
      "    (wx): Linear(in_features=512, out_features=512, bias=False)\n",
      "    (ws): Linear(in_features=512, out_features=3, bias=True)\n",
      "  )\n",
      "  (position_encodings): PositionalEncoding(\n",
      "    (dropout): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      "  (multihead_attn): MultiheadAttention(\n",
      "    (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
      "  )\n",
      "  (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (attn_dropout): Dropout(p=0.2, inplace=False)\n",
      "  (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "  (out_dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n",
      "epoch 1, loss 0.2661, train acc 0.517, test acc 0.444, time 91.0 sec\n",
      "epoch 2, loss 0.1149, train acc 0.612, test acc 0.666, time 88.6 sec\n",
      "epoch 3, loss 0.0565, train acc 0.686, test acc 0.602, time 92.1 sec\n",
      "epoch 4, loss 0.0384, train acc 0.736, test acc 0.650, time 96.3 sec\n",
      "epoch 5, loss 0.0269, train acc 0.759, test acc 0.656, time 100.1 sec\n",
      "epoch 6, loss 0.0193, train acc 0.795, test acc 0.684, time 98.9 sec\n",
      "epoch 7, loss 0.0141, train acc 0.828, test acc 0.707, time 107.7 sec\n",
      "epoch 8, loss 0.0105, train acc 0.855, test acc 0.718, time 104.5 sec\n",
      "epoch 9, loss 0.0081, train acc 0.872, test acc 0.726, time 101.5 sec\n",
      "epoch 10, loss 0.0060, train acc 0.893, test acc 0.739, time 108.5 sec\n",
      "epoch 11, loss 0.0049, train acc 0.904, test acc 0.735, time 110.3 sec\n",
      "epoch 12, loss 0.0040, train acc 0.921, test acc 0.732, time 107.9 sec\n",
      "epoch 13, loss 0.0034, train acc 0.928, test acc 0.747, time 99.4 sec\n",
      "epoch 14, loss 0.0027, train acc 0.937, test acc 0.738, time 119.9 sec\n",
      "epoch 15, loss 0.0024, train acc 0.941, test acc 0.727, time 108.1 sec\n",
      "epoch 16, loss 0.0021, train acc 0.953, test acc 0.722, time 97.7 sec\n",
      "epoch 17, loss 0.0017, train acc 0.961, test acc 0.738, time 113.4 sec\n",
      "epoch 18, loss 0.0014, train acc 0.960, test acc 0.733, time 117.3 sec\n",
      "epoch 19, loss 0.0011, train acc 0.968, test acc 0.721, time 111.6 sec\n",
      "epoch 20, loss 0.0009, train acc 0.974, test acc 0.726, time 103.3 sec\n"
     ]
    }
   ],
   "source": [
    "embedding_dim, num_hiddens, num_layers = 300, 256, 1\n",
    "net = ATAE_GRU_Position_SA(embedding_dim, num_hiddens, num_layers).to(device)\n",
    "print(net)\n",
    "lr, num_epochs = 0.001, 20\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "loss = nn.CrossEntropyLoss(reduction=\"none\")\n",
    "sa_data = train_sa(train_iter, val_iter, net, loss, optimizer, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "355"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del net\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(data, name):\n",
    "    \n",
    "    epoch, train_loss, train_acc, test_acc, time = data\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(epoch, train_loss)\n",
    "    plt.title(\"Training loss\")\n",
    "\n",
    "    #plot 2:\n",
    "    x = np.array([1, 2, 3, 4])\n",
    "    y = np.array([1, 4, 9, 16])\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(epoch, train_acc)\n",
    "    plt.title(\"Training Acc\")\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.plot(epoch, test_acc)\n",
    "    plt.title(\"Test Acc\")\n",
    "\n",
    "    plt.suptitle(name)\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(lstm_data, \"ATAE_LSTM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(gru_data, \"ATAE_GRU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(pos_data, \"ATAE_GRU_POS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(sa_data, \"ATAE_LSTM_POS_SA\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d9361009f824c5a3a0548ad660b971fcdd9e286ba81e792997e4020d851e4559"
  },
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
